import pygame
from snake_game import SnakeGameAI, Direction
from dqn_agent import Agent
import numpy as np

def play_human():
    """Play Snake manually with arrow keys - enhanced with obstacle information"""
    print("Select game speed:")
    print("1. Slow (10 FPS) - Easy to see")
    print("2. Medium (20 FPS) - Balanced")  
    print("3. Fast (30 FPS) - Challenge")
    print("4. Very Fast (40 FPS) - Expert")
    
    try:
        choice = int(input("Choose speed (1-4): "))
        speeds = {1: 10, 2: 20, 3: 30, 4: 40}
        selected_speed = speeds.get(choice, 20)
    except:
        selected_speed = 20
        
    game = SnakeGameAI(speed=selected_speed)
    
    print("üéÆ Human Controls:")
    print("   ‚¨ÖÔ∏è Left Arrow: Turn Left")
    print("   ‚û°Ô∏è Right Arrow: Turn Right")
    print("   + Key: Increase speed")
    print("   - Key: Decrease speed")
    print("   üü† Orange blocks: Moving obstacles (avoid them!)")
    print("   üçé Red block: Food (collect it!)")
    print("   üéØ CHALLENGE: Start with 6 obstacles, +1 per food eaten!")
    print("   Press ESC to quit")
    
    while True:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                pygame.quit()
                quit()
            elif event.type == pygame.KEYDOWN:
                if event.key == pygame.K_ESCAPE:
                    pygame.quit()
                    quit()
                
        # Human controls
        keys = pygame.key.get_pressed()
        action = [1, 0, 0]  # Default: straight
        
        if keys[pygame.K_LEFT]:
            action = [0, 0, 1]  # Left
        elif keys[pygame.K_RIGHT]:
            action = [0, 1, 0]  # Right
            
        reward, game_over, score = game.play_step(action)
        
        if game_over:
            obstacle_count = len(game.obstacles) if hasattr(game, 'obstacles') else 0
            print(f'üéØ Game Over! Final Score: {score} | Max Obstacles Reached: {obstacle_count}')
            
            # Analyze cause of death
            head = game.head
            if head.x < 0 or head.x >= game.w or head.y < 0 or head.y >= game.h:
                print("üí• Collision cause: Hit wall")
            elif head in game.snake[1:]:
                print("üí• Collision cause: Hit yourself")
            else:
                obstacle_positions = [obs['pos'] for obs in game.obstacles]
                if head in obstacle_positions:
                    print("üí• Collision cause: Hit moving obstacle")
                    
            if score > 0:
                print(f"üèÜ Impressive! You survived {score} food collections with increasing obstacles!")
            
            play_again = input("Play again? (y/n): ").lower()
            if play_again == 'y':
                game.reset()
            else:
                break

def play_ai():
    """Watch trained AI play Snake with enhanced debugging"""
    print("Select viewing speed:")
    print("1. Slow (10 FPS) - Easy to watch")
    print("2. Medium (20 FPS) - Balanced")  
    print("3. Fast (30 FPS) - Quick training")
    print("4. Very Fast (40 FPS) - Maximum speed")
    
    try:
        choice = int(input("Choose speed (1-4): "))
        speeds = {1: 10, 2: 20, 3: 30, 4: 40}
        selected_speed = speeds.get(choice, 20)
    except:
        selected_speed = 20
    
    agent = Agent()
    game = SnakeGameAI(speed=selected_speed)
    
    # Initialize the model first by getting a state
    dummy_state = agent.get_state(game)
    
    # Set epsilon to 0 for pure exploitation
    agent.epsilon = 0
    agent.n_games = 1000  # Ensure epsilon calculation gives 0
    
    # Load trained model
    try:
        import torch
        agent.model.load_state_dict(torch.load('./models/model.pth'))
        print("‚úÖ Loaded trained model!")
        print(f"üß† Agent epsilon: {agent.epsilon}")
        print(f"üéÆ Agent games trained: {agent.n_games}")
        print(f"üé¨ Viewing at {selected_speed} FPS (press +/- to adjust)")
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        print("üí° Make sure you have trained a model first (option 2 or 3)")
        return
    game_count = 0
    total_score = 0
    obstacle_collisions = 0
    successful_games = 0
    
    print("\nü§ñ AI Playing Snake with Dynamic Moving Obstacles")
    print("üéØ Challenge: Start with 6 obstacles, +1 per food eaten!")
    print("üìä Statistics will be shown every 10 games")
    print("‚èπÔ∏è Press Ctrl+C to stop watching")
    print("-" * 50)
    
    try:
        while True:
            state = agent.get_state(game)
            action = agent.get_action(state)
            reward, game_over, score = game.play_step(action)
            
            if game_over:
                game_count += 1
                total_score += score
                
                # Analyze performance
                head = game.head
                if score > 0:
                    successful_games += 1
                    
                # Check if it was an obstacle collision
                obstacle_positions = [obs['pos'] for obs in game.obstacles]
                if head in obstacle_positions:
                    obstacle_collisions += 1
                
                max_obstacles = len(game.obstacles) if hasattr(game, 'obstacles') else 0
                print(f'üéØ AI Game {game_count}: Score {score} | Max Obstacles: {max_obstacles}')
                
                # Detailed statistics every 10 games
                if game_count % 10 == 0:
                    avg_score = total_score / game_count
                    obstacle_collision_rate = (obstacle_collisions / game_count) * 100
                    success_rate = (successful_games / game_count) * 100
                    
                    print(f"\nüìà Statistics after {game_count} games:")
                    print(f"   Average Score: {avg_score:.2f}")
                    print(f"   Success Rate (Score > 0): {success_rate:.1f}%")
                    print(f"   Obstacle Collision Rate: {obstacle_collision_rate:.1f}%")
                    print(f"   Total Food Collected: {total_score}")
                    
                    # Show AI's current understanding
                    print(f"   üß† AI State Analysis:")
                    print(f"      Current epsilon: {agent.epsilon}")
                    print(f"      State vector size: {len(state)}")
                    print(f"      Action taken: {['Straight', 'Right', 'Left'][action.index(1)]}")
                    print("-" * 50)
                
                game.reset()
                
    except KeyboardInterrupt:
        print(f"\nüìä Final AI Performance Summary:")
        print(f"   Games played: {game_count}")
        print(f"   Average score: {total_score/max(1,game_count):.2f}")
        print(f"   Obstacle avoidance: {((game_count-obstacle_collisions)/max(1,game_count)*100):.1f}%")
        print(f"   Success rate: {(successful_games/max(1,game_count)*100):.1f}%")

def compare_models():
    """Compare performance of different saved models"""
    import os
    models_dir = './models'
    
    if not os.path.exists(models_dir):
        print("‚ùå No models directory found. Train a model first!")
        return
    
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
    
    if not model_files:
        print("‚ùå No model files found. Train a model first!")
        return
    
    # Sort by modification time (newest first)
    model_files_with_time = []
    for f in model_files:
        full_path = os.path.join(models_dir, f)
        mod_time = os.path.getmtime(full_path)
        model_files_with_time.append((f, mod_time))
    
    model_files_with_time.sort(key=lambda x: x[1], reverse=True)
    
    print("üîç Available models (sorted by newest first):")
    for i, (model_file, _) in enumerate(model_files_with_time):
        print(f"   {i+1}. {model_file}")
    
    try:
        choice = int(input("Select model to test (number): ")) - 1
        if choice < 0 or choice >= len(model_files_with_time):
            print("‚ùå Invalid choice")
            return
        
        selected_model = model_files_with_time[choice][0]
        print(f"üß™ Testing model: {selected_model}")
        
        # Test the selected model
        agent = Agent()
        game = SnakeGameAI()
        
        # Initialize the model first
        dummy_state = agent.get_state(game)
        agent.set_inference_mode()  # No exploration for testing
        
        import torch
        agent.model.load_state_dict(torch.load(os.path.join(models_dir, selected_model)))
        
        # Run quick performance test
        scores = []
        obstacle_hits = 0
        max_obstacles_reached = 6
        
        print(f"üß™ Running 20 test games with {selected_model}...")
        
        for test_game in range(20):  # Test 20 games
            max_obstacles_this_game = 6
            while True:
                state = agent.get_state(game)
                action = agent.get_action(state)
                reward, done, score = game.play_step(action)
                
                # Track max obstacles reached this game
                current_obstacles = len(game.obstacles) if hasattr(game, 'obstacles') else 6
                max_obstacles_this_game = max(max_obstacles_this_game, current_obstacles)
                
                if done:
                    scores.append(score)
                    max_obstacles_reached = max(max_obstacles_reached, max_obstacles_this_game)
                    
                    # Check if obstacle collision
                    head = game.head
                    obstacle_positions = [obs['pos'] for obs in game.obstacles]
                    if head in obstacle_positions:
                        obstacle_hits += 1
                    
                    print(f"Test game {test_game + 1}: Score {score}, Max obstacles: {max_obstacles_this_game}")
                    game.reset()
                    break
        
        avg_score = sum(scores) / len(scores)
        max_score = max(scores)
        min_score = min(scores)
        obstacle_avoidance = ((20 - obstacle_hits) / 20) * 100
        success_rate = (len([s for s in scores if s > 0]) / 20) * 100
        
        print(f"\nüìä Model Performance Analysis ({selected_model}):")
        print(f"   Average Score: {avg_score:.2f}")
        print(f"   Best Score: {max_score}")
        print(f"   Worst Score: {min_score}")
        print(f"   Success Rate (Score > 0): {success_rate:.1f}%")
        print(f"   Obstacle Avoidance: {obstacle_avoidance:.1f}%")
        print(f"   Max Obstacles Reached: {max_obstacles_reached}")
        print(f"   Score Distribution: {scores}")
        
        # Performance rating
        if avg_score >= 10:
            rating = "üèÜ EXCELLENT"
        elif avg_score >= 5:
            rating = "ü•à GOOD"
        elif avg_score >= 2:
            rating = "ü•â DECENT"
        else:
            rating = "üìà NEEDS IMPROVEMENT"
            
        print(f"   Overall Rating: {rating}")
        
    except ValueError:
        print("‚ùå Please enter a valid number")
    except Exception as e:
        print(f"‚ùå Error testing model: {e}")

def menu():
    """Enhanced main menu"""
    print("\nüêç Snake AI Project with Enhanced Moving Obstacles ü§ñ")
    print("=" * 55)
    print("1. üéÆ Play Snake manually (with moving obstacles)")
    print("2. ü§ñ Train AI (console only - recommended)")
    print("3. üìà Train AI with adaptive obstacles")
    print("4. üëÄ Watch AI play (load existing model)")
    print("5. üîç Compare/Test different models")
    print("6. ‚ÑπÔ∏è  Show training tips")
    print("7. üö™ Exit")
    
    choice = input("\nSelect option (1-7): ")
    
    if choice == '1':
        play_human()
    elif choice == '2':
        from train import train
        train()
    elif choice == '3':
        from train import train_with_adaptive_obstacles
        train_with_adaptive_obstacles()
    elif choice == '4':
        play_ai()
    elif choice == '5':
        compare_models()
    elif choice == '6':
        show_training_tips()
    elif choice == '7':
        print("Goodbye! üëã")
        exit()
    else:
        print("‚ùå Invalid choice!")
        menu()

def show_training_tips():
    """Show training tips and information"""
    print("\nüìö Training Tips for Dynamic Obstacle Avoidance:")
    print("=" * 55)
    print("üéØ Goal: Train AI to collect food while avoiding increasing obstacles")
    print("üî• Challenge: Each food eaten adds 1 more moving obstacle!")
    print()
    print("üìà Training Progression:")
    print("   ‚Ä¢ Early games (0-100): Learning basic movement with 2 obstacles")
    print("   ‚Ä¢ Mid training (100-500): Adapting to 3-6 obstacles")
    print("   ‚Ä¢ Advanced (500+): Mastering complex scenarios with 7+ obstacles")
    print()
    print("üìä Key Metrics to Watch:")
    print("   ‚Ä¢ Obstacle collision rate should decrease over time")
    print("   ‚Ä¢ Average score should gradually increase despite difficulty")
    print("   ‚Ä¢ AI should learn to survive longer with more obstacles")
    print()
    print("üß† Neural Network Features:")
    print("   ‚Ä¢ Dynamic input size (adapts to state complexity)")
    print("   ‚Ä¢ Multi-distance obstacle detection")
    print("   ‚Ä¢ Movement pattern analysis")
    print("   ‚Ä¢ Adaptive exploration (slower decay for increasing difficulty)")
    print()
    print("‚öôÔ∏è Dynamic Difficulty System:")
    print("   ‚Ä¢ Starts with 2 obstacles")
    print("   ‚Ä¢ +1 obstacle per food eaten")
    print("   ‚Ä¢ Rewards scale with difficulty (more obstacles = bigger rewards)")
    print("   ‚Ä¢ Timeout scales with obstacle count")
    print()
    print("üí° Pro Tips:")
    print("   ‚Ä¢ Train for 1000+ games due to increasing complexity")
    print("   ‚Ä¢ Watch for AI learning to balance risk vs reward")
    print("   ‚Ä¢ Higher scores become exponentially more impressive")
    print("   ‚Ä¢ AI must develop long-term survival strategies")
    
    input("\nPress Enter to return to menu...")

if __name__ == '__main__':
    menu()